---
title: "How to identify the correct way of doing barbell lifts"
author: "Simone Krämer"
date: "16 Februar 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
library(knitr)
library(markdown)
library(parallel)
library(doParallel)
library(caret)
library(ggplot2)
library(printr)
```

# Introduction
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. 

# Used Data
The data can be obtained on the webpage http://groupware.les.inf.puc-rio.br/har.
For more information about the data itself, please refer to "Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13). Stuttgart, Germany: ACM SIGCHI, 2013".

```{r, cache = TRUE}
trainData <- read.csv('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv')
validationData <- read.csv('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv')
```
The target of this project is to determine whether 6 different people did barbell lifts in 
a correct way. The correctness can be seen in the "Classe" variable. The meaning of this variable
is as follows:  
  
- A: according to the specification  
- B: throwing the elbows to the front  
- C: lifting the dumbbell only halfway  
- D: lowering the dumbbell only halfway  
- E: throwing the hips to the front  

# Prepare data for model fitting
As there are 160 predictors, they will be reduced in order to get a simpler model with
a better fit. Besides raw values for each accelerometer, there are statistical values
such as "skewness", "min", "max", etc. These will be taken out. Also, the user name,
time stamps and windows are taken out.
```{r, cache = TRUE}
unneededVar <- c("skewness", "min", "max", "amplitude", "avg", "stddev", "var",
                 "kurtosis", "user_name", "timestamp", "window", "X")
maskSubset <- !grepl(paste(unneededVar, collapse = "|"),
                     colnames(trainData))
trainData <- trainData[, maskSubset]
validationData <- validationData[, maskSubset]
```
  
In the next step, the training set will be divided in a test and a train set:
```{r, cache = TRUE}
set.seed(2602)
inTrain <- createDataPartition(y = trainData$classe, p = 0.7, list = FALSE)
training <- trainData[inTrain, ]
testing <- trainData[-inTrain, ]
```
  
# Model fitting
For model fit, the random forest method will be used. In order to make it faster,
parallel computing will be used and 5-fold cross validation resampling method:
```{r, cache = TRUE}
# Configure parallel processing
cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

# Configure trainControl object
fitControl <- trainControl(method = "cv",
                           number = 5,
                           allowParallel = TRUE)

# Fit model
modFit <- train(classe ~ ., data = training, method = 'rf', trControl = fitControl)

# De-register parallel processing cluster
stopCluster(cluster)
registerDoSEQ()
```
  
# Check model fit with test data
In order to check the model quality, it will be applied to the test dataset:
```{r, echo = TRUE}
predTest <- predict(modFit, testing)
confMat <- confusionMatrix(predTest, testing$classe)
confMat
```
  
The prediction result looks very good with a model accuracy of 99.24%. It is also
interesting to know the 20 most important parameters:

```{r, echo = TRUE}
varImp <- varImp(modFit)
varImp
```
  
The distinction of the classes are shown in a plot with the two most important predictors:
```{r}
g <- ggplot(data = testing, aes(roll_belt, yaw_belt, color = classe))
g <- g + geom_point() + xlab("roll_belt") + ylab("yaw_belt")
g
```
  
It can be seen that it is not possible to distinguish the classes just with these
two predictors, however, some definite clusters can be seen.
  
# Prediction on validation set
As this model looks good, the prediction on the validation set can be made:
```{r, echo = TRUE}
predVal <- predict(modFit, newdata = validationData)
predVal
```
